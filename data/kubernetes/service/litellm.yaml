---
ingress_class: contour-compute
service_name: llm

values:
  ingress:
    enabled: true
    annotations:
      projectcontour.io/response-timeout: infinity
    className: "%{lookup('ingress_class')}"
    hosts:
      - host: "%{nest::kubernetes::fqdn}"
        paths:
          - path: /
            pathType: ImplementationSpecific

  proxy_config:
    model_list:
      # General reasoning
      - model_name: gpt-oss-120b
        litellm_params:
          model: openai/general
          api_base: http://llama-general/v1
          api_key: none
          # temperature: 0.7

      # Coding
      - model_name: qwen3-coder-30b
        litellm_params:
          model: openai/coder
          api_base: http://llama-coder/v1
          api_key: none
          # temperature: 0.2

      # Multimodal assistant
      - model_name: gemma-3-4b
        litellm_params:
          model: openai/multi
          api_base: http://llama-multi/v1
          api_key: none
          # temperature: 0.2
        model_info:
          supports_vision: True

      # Utility
      - model_name: ministral-3-3b
        litellm_params:
          model: openai/util
          api_base: http://llama-util:8080/v1
          api_key: none
          temperature: 0.1
