---
ingress_class: contour-compute
service_name: llm

values:
  ingress:
    enabled: true
    annotations:
      projectcontour.io/response-timeout: infinity
    className: "%{lookup('ingress_class')}"
    hosts:
      - host: "%{nest::kubernetes::fqdn}"
        paths:
          - path: /
            pathType: ImplementationSpecific
  proxy_config:
    model_list:
      - model_name: gpt-oss-120b
        litellm_params:
          model: openai/general
          api_base: http://llama-general/v1
          api_key: none
      - model_name: qwen3-coder-30b
        litellm_params:
          model: openai/coder
          api_base: http://llama-coder/v1
          api_key: none
